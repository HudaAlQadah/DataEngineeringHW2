{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5388a057-3dce-417f-86d2-9acab09b45fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting apache-airflow\n",
      "  Downloading apache_airflow-2.3.2-py3-none-any.whl (5.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m728.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -U apache-airflow\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "from airflow import DAG\n",
    "from airflow.operators.bash_operator import BashOperator\n",
    "from airflow.operators.python_operator import PythonOperator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beafb00b-6dbb-4a7a-b7ac-3f37479451a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def Get_DF_i(Day):\n",
    "        import pandas as pd\n",
    "        DF_i=None\n",
    "        try: \n",
    "            URL_Day=f'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/{Day}.csv'\n",
    "            DF_day=pd.read_csv(URL_Day)\n",
    "            DF_day['Day']=Day\n",
    "            cond=(DF_day.Country_Region=='United Kingdom')\n",
    "            Selec_columns=['Day','Country_Region', 'Last_Update',\n",
    "                  'Lat', 'Long_', 'Confirmed', 'Deaths', 'Recovered', 'Active',\n",
    "                  'Combined_Key', 'Incident_Rate', 'Case_Fatality_Ratio']\n",
    "            DF_i=DF_day[cond][Selec_columns].reset_index(drop=True)\n",
    "        except:\n",
    "            print(f'{Day} is not available!')\n",
    "            pass\n",
    "        return DF_i\n",
    "\n",
    "def Create_data():\n",
    "        import pandas as pd\n",
    "        List_of_Days=[]\n",
    "        import datetime\n",
    "        for i in range(1,145):\n",
    "                Previous_Date = datetime.datetime.today() - datetime.timedelta(days=145-i)\n",
    "                if (Previous_Date.day >9):\n",
    "                    if (Previous_Date.month >9):\n",
    "                          List_of_Days.append(f'{Previous_Date.month}-{Previous_Date.day}-{Previous_Date.year}')\n",
    "                    else:\n",
    "                          List_of_Days.append(f'0{Previous_Date.month}-{Previous_Date.day}-{Previous_Date.year}')\n",
    "                else:\n",
    "                    if (Previous_Date.month >9):\n",
    "                          List_of_Days.append(f'{Previous_Date.month}-0{Previous_Date.day}-{Previous_Date.year}')\n",
    "                    else:\n",
    "                          List_of_Days.append(f'0{Previous_Date.month}-0{Previous_Date.day}-{Previous_Date.year}')\n",
    "            \n",
    "        DF_all=[]\n",
    "        for Day in List_of_Days:\n",
    "            DF_all.append(Get_DF_i(Day))\n",
    "            \n",
    "        DF_UK=pd.concat(DF_all).reset_index(drop=True)\n",
    "        DF_UK['Last_Update']=pd.to_datetime(DF_UK.Last_Update, infer_datetime_format=True)  \n",
    "        DF_UK['Day']=pd.to_datetime(DF_UK.Day, infer_datetime_format=True)  \n",
    "        DF_UK['Case_Fatality_Ratio']=DF_UK['Case_Fatality_Ratio'].astype(float)\n",
    "        DF_UK.set_index('Day', inplace=True)\n",
    "        DF_UK.to_csv('/opt/airflow/data/DF_UK.csv')\n",
    "\n",
    "def MinMaxScaler():\n",
    "        import pandas as pd\n",
    "        import sklearn\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        DF_UK = pd.read_csv('/opt/airflow/data/DF_UK.csv', parse_dates=['Last_Update'])\n",
    "        DF_UK['Day']=DF_UK.Day\n",
    "        DF_UK.set_index('Day', inplace=True)\n",
    "        min_max_scaler = MinMaxScaler()\n",
    "        DF_UK_u=DF_UK.copy()\n",
    "        Select_Columns=['Confirmed','Deaths', 'Recovered', 'Active','Case_Fatality_Ratio']\n",
    "        DF_UK_2=DF_UK_u[Select_Columns]\n",
    "        DF_UK_3 = pd.DataFrame(min_max_scaler.fit_transform(DF_UK_2[Select_Columns]),columns=Select_Columns)\n",
    "        DF_UK_3['Day']=DF_UK_u.index\n",
    "        DF_UK_3.set_index('Day', inplace=True)\n",
    "        DF_UK_3.to_csv('/opt/airflow/data/DF_UK_Scaled.csv')\n",
    "\n",
    "def Plotting():\n",
    "        import pandas as pd \n",
    "        import matplotlib.pyplot as plt\n",
    "        DF_UK_u_3 = pd.read_csv('/opt/airflow/data/DF_UK_Scaled.csv', parse_dates=['Day'])\n",
    "        DF_UK_u_3.set_index('Day', inplace=True) \n",
    "        Select_Columns=['Confirmed','Deaths', 'Recovered', 'Active','Case_Fatality_Ratio']\n",
    "        DF_UK_u_3[Select_Columns].plot(figsize=(30,20))\n",
    "        plt.savefig('/opt/airflow/output/UK_scoring_report.png')\n",
    "    \n",
    "\n",
    "def CSV_to_Postgres():\n",
    "        import sqlalchemy\n",
    "        from sqlalchemy import create_engine\n",
    "        import pandas as pd\n",
    "\n",
    "        DF_UK_Scaled = pd.read_csv('/opt/airflow/data/UK_scoring_report.csv', parse_dates=['Day'])\n",
    "        DF_UK_Scaled.set_index('Day', inplace=True)\n",
    "\n",
    "        host=\"postgresDev\"\n",
    "        database=\"testDB\"\n",
    "        user=\"me\"\n",
    "        password=\"1234\"\n",
    "        port='5432'\n",
    "        engine = create_engine(f'postgresql://{user}:{password}@{host}:{port}/{database}')\n",
    "        DF_UK_Scaled.to_sql('UK_scoring_report', engine,if_exists='replace',index=False)    \n",
    "\n",
    " \n",
    " \n",
    "default_args = {\n",
    "    'owner': 'Huda',\n",
    "    'start_date': dt.datetime(2022, 5, 30),\n",
    "    'retries': 1,\n",
    "    'retry_delay': dt.timedelta(minutes=1),\n",
    "}\n",
    " \n",
    "with DAG('UK_COVID19_dag',\n",
    "         default_args=default_args,\n",
    "         schedule_interval=timedelta(days=1),  \n",
    "         catchup=False,     \n",
    "         ) as dag:\n",
    "    \n",
    "    Install_dependecies = BashOperator(task_id='Install_dependecies',bash_command='pip install sklearn matplotlib')   \n",
    "    Extract_Data = PythonOperator(task_id='Extract_UK_Data', python_callable=Create_data)\n",
    "    Scaled_Data = PythonOperator(task_id='Scale_UK_Data', python_callable=MinMaxScaler)\n",
    "    Ploting_Data = PythonOperator(task_id='Plot_UK_Data', python_callable=Plotting)\n",
    "    Push_Data_to_Postgres = PythonOperator(task_id='Push_Data_to_Postgres', python_callable=CSV_to_Postgres)\n",
    "\n",
    " \n",
    " \n",
    " \n",
    "\n",
    "Install_dependecies >> Extract_Data >> Scaled_Data >> Ploting_Data >> Push_Data_to_Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e27549-97d9-4efc-b853-17152598f58b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df8460c-118e-447f-a448-d40367e38880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
